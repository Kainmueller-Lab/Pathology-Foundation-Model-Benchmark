project: patho_benchmark
experiment: unetr1.4
experiment_path: experiments
training_steps: 10000
log_interval: 10
val_interval: 200
multiprocessing: true
num_workers: 4
seed: 42
primary_metric: f1_score_macro
save_all_ckpts: false # watch out for storage
early_stopping: 1200

dataset:
  name: 'schuerch'
  batch_size: 64
  uniform_class_sampling: True
  sample_excluded_classes: False
  path: /fast/AG_Kainmueller/data/patho_foundation_model_bench_data/schuerch_dataset_lmdb/lmdb
  split: /fast/AG_Kainmueller/data/patho_foundation_model_bench_data/schuerch_dataset_lmdb/splits/schuerch_dataset_split.csv
  label_dict: /fast/AG_Kainmueller/data/patho_foundation_model_bench_data/schuerch_dataset_lmdb/label_dict.json
  
model:
  model_wrapper: UnetR
  backbone: musk #provgigapath, uni, uni2, musk, titan, virchow2, phikonv2
  unfreeze_backbone: false

optimizer:
  name: AdamW
  params:
    lr: 1e-5
    weight_decay: 0.03
  warmup_steps: 1000

scheduler:
  name: CosineAnnealingLR
  params:
    T_max: 10000
    eta_min: 1e-6

loss_fn:
  name: CrossEntropyLoss
  params:
    label_smoothing: 0.05
    reduction: none
  class_weighting: true

  exclude_classes: [0]

augmentations:
  RandomHorizontalFlip:
    p: 0.5
  RandomVerticalFlip:
    p: 0.5
  RandomAffine:
    degrees: [0, 360]
    translate: 0.1
    scale: [0.8, 1.2]  # Changed 0.2 to [min_scale, max_scale]
    resample: BILINEAR
  RandomElasticTransform:
    kernel_size: [63, 63]
    sigma: [32.0, 32.0]
    alpha: [1.0, 1.0]  # Changed from alpha_affine to alpha
  HEDNormalize:
    sigma: 0.025 # halved color aug
    bias: 0.05 # halved color aug
